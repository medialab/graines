{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial data and rename the id as user_id\n",
    "data = pd.read_csv('data/2000_followers_graines_version_2021_09_21 (1).csv', index_col = [0])\n",
    "data = data.rename(columns = {'id':'user_id'})\n",
    "list_user = list(data.user_id)\n",
    "\n",
    "# Load and concat the embeddings\n",
    "emb = {}\n",
    "emb['bert'] = np.load('embeddings/bert.npy')\n",
    "emb['features'] = np.load('embeddings/features.npy')\n",
    "emb['profile_pictures'] = np.load('embeddings/full_profile_pictures.npy')\n",
    "emb['tfidf'] = np.load('embeddings/tfidf.npy')\n",
    "\n",
    "full_list = (emb['tfidf'], emb['profile_pictures'], emb['features'], emb['bert'])\n",
    "\n",
    "X = np.concatenate(full_list, axis=1)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "X = pd.DataFrame(emb['tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concat the annotations\n",
    "data_1 = pd.read_csv('data/data annotated/project-116-at-2021-10-11-12-14-ffdbfe39.csv')\n",
    "data_2 = pd.read_csv('data/data annotated/project-118-at-2021-10-11-12-13-e2172a5e.csv')\n",
    "\n",
    "df_ann = pd.concat([data_1, data_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the initial data and the results of the annotations based on similar various keys\n",
    "key = ['screen_name', 'name', 'description', 'protected', 'location']\n",
    "merged = pd.merge(data[key + ['user_id']], df_ann, on = key, how = 'left')\n",
    "\n",
    "# Deal with the common data (I just randomly keep one )\n",
    "merged = merged.drop_duplicates(['user_id'], keep='first')\n",
    "merged = merged[['user_id', 'sentiment']]\n",
    "merged = merged.reset_index(drop=True)\n",
    "\n",
    "# Deal with data that have not been annotated\n",
    "merged_fin = merged[merged.sentiment.notna()].reset_index(drop=True)\n",
    "\n",
    "# Erase the values with the X\n",
    "index_notnan = merged.index[merged['sentiment'].notna()]\n",
    "X_fin = np.array(X.iloc[index_notnan])\n",
    "\n",
    "# Get the Y labels\n",
    "map_code = {'non-graine':0, 'graine':1}\n",
    "merged_fin['sentiment'] = merged_fin['sentiment'].map(map_code)\n",
    "y_fin = np.array(merged_fin.sentiment)\n",
    "\n",
    "# Save the data\n",
    "np.save('data/final_X.npy', X_fin)\n",
    "np.save('data/final_y.npy', y_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, euclidean_distances\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def triangular_kernel(X, Y):\n",
    "    return 1 - abs(euclidean_distances(X, Y))\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"SVM_triangular_kernel\": SVC(kernel=triangular_kernel, C=3),\n",
    "    \"SVM_RBF_kernel\": SVC(),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1205\n",
      "1       2\n",
      "dtype: int64\n",
      "0.5 0.011904761904761904 0.023255813953488372\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fin, y_fin, test_size=0.7, random_state=26)\n",
    "\n",
    "clf = classifiers['SVM_triangular_kernel']\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(pd.DataFrame(y_pred).value_counts())\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                y_test, y_pred, pos_label=1, average=\"binary\"\n",
    "            )\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
