{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bamboolib\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (1/np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the graines, their friends & their followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the followers of the graines\n",
    "foll = pd.read_csv('data/followers_graines_version_2021_09_21.csv', index_col = [0], low_memory=False).reset_index()\n",
    "foll = foll[['twitter_handle', 'follower_id']]\n",
    "\n",
    "# Create the dictionary of graines and their followers\n",
    "group_foll = foll.groupby('twitter_handle')['follower_id'].count().rename('count_followers').reset_index()\n",
    "dict_follo = dict(zip(group_foll['twitter_handle'], group_foll['count_followers']) )\n",
    "\n",
    "# Load of the friends of the graines\n",
    "fri = pd.read_csv('data/friends_graines.csv.gz', index_col = [0], low_memory=False).reset_index()\n",
    "fri = fri[['twitter_handle', 'friend_id']]\n",
    "\n",
    "# Create the dictionary of graines and their friends\n",
    "group_fri = fri.groupby('twitter_handle')['friend_id'].count().rename('count_friends').reset_index()\n",
    "dict_fri = dict(zip(group_fri['twitter_handle'], group_fri['count_friends']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the missing values of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of the candidates\n",
    "data_candidate = pd.read_csv('data/data_ready.csv', index_col = [0])\n",
    "data = data_candidate[['user_id', 'followers', 'friends', 'count_graines_in_friends', 'graines_in_friends']]\n",
    "data['graines_in_friends'] = data['graines_in_friends'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The followers information of the original dataset is missing\n",
    "foll_grain = pd.merge(data, foll, left_on = 'user_id', right_on = 'follower_id').drop('follower_id', axis=1)\n",
    "foll_grain = foll_grain.groupby('user_id')['twitter_handle'].agg(['count', list])\n",
    "foll_grain.columns = ['count_graines_in_followers', 'graines_in_followers']\n",
    "foll_grain = foll_grain.reset_index()\n",
    "\n",
    "# remerge with the datase\n",
    "new_data = pd.merge(foll_grain, data, on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_follo = new_data.explode('graines_in_followers')\n",
    "new_data_follo['total_grain_follo'] = new_data_follo['graines_in_followers'].apply(lambda x: dict_follo.get(x))\n",
    "\n",
    "# get the sum of the total followers of graine follows by an indivual\n",
    "new_data_follo = new_data_follo.groupby('user_id')['total_grain_follo'].sum().reset_index()\n",
    "\n",
    "# Normalize by the formula\n",
    "new_data_follo['normalize_follo'] = new_data_follo['total_grain_follo'].apply(lambda x: norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_fri = new_data.explode('graines_in_friends')\n",
    "new_data_fri['total_grain_fri'] = new_data_fri['graines_in_friends'].apply(lambda x: dict_fri.get(x))\n",
    "\n",
    "# get the sum of the total followers of graine follows by an indivual\n",
    "new_data_fri = new_data_fri.groupby('user_id')['total_grain_fri'].sum().reset_index()\n",
    "\n",
    "# Normalize by the formula\n",
    "new_data_fri['normalize_friends'] = new_data_fri['total_grain_fri'].apply(lambda x: norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_score = pd.merge(new_data_follo, new_data_fri, on = 'user_id')\n",
    "concat_score = pd.merge(concat_score, new_data, on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_score['prop_graine_friends'] = concat_score['count_graines_in_friends']/concat_score['friends']\n",
    "concat_score['prop_graine_followers'] = concat_score['count_graines_in_followers']/concat_score['followers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = concat_score[['count_graines_in_followers', 'prop_graine_followers',\n",
    "                    'count_graines_in_friends', 'prop_graine_friends', \n",
    "                    'normalize_friends', 'normalize_follo']]\n",
    "\n",
    "\n",
    "\n",
    "final = final.fillna(final.mean())\n",
    "final = final.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "final = np.array(final)\n",
    "np.save('embeddings/topo.npy', final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(data_candidate.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-7418253d339b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification\n",
    "cls = autosklearn.classification.AutoSklearnClassifier()\n",
    "cls.fit(X_train, y_train)\n",
    "predictions = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement autosklearn (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for autosklearn\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install autosklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
